{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Emotion Detection with TensorFlow, MobileNetV2 and OpenCV\n", "\n", "# Install required libraries\n", "!pip install tensorflow opencv-python matplotlib\n", "\n", "# Import required packages\n", "import tensorflow as tf\n", "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n", "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n", "import numpy as np\n", "import cv2\n", "import os\n", "import matplotlib.pyplot as plt\n", "\n", "# Prepare data generators for training and validation\n", "train_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, zoom_range=0.2)\n", "val_gen = ImageDataGenerator(rescale=1./255)\n", "\n", "train_data = train_gen.flow_from_directory(\n", "    'data/train',\n", "    target_size=(224, 224),\n", "    batch_size=32,\n", "    class_mode='categorical'\n", ")\n", "\n", "val_data = val_gen.flow_from_directory(\n", "    'data/validation',\n", "    target_size=(224, 224),\n", "    batch_size=32,\n", "    class_mode='categorical'\n", ")\n", "\n", "# Build the model using MobileNetV2 for transfer learning\n", "base_model = tf.keras.applications.MobileNetV2(\n", "    input_shape=(224, 224, 3),\n", "    include_top=False,\n", "    weights='imagenet'\n", ")\n", "base_model.trainable = False\n", "\n", "model = tf.keras.Sequential([\n", "    base_model,\n", "    tf.keras.layers.GlobalAveragePooling2D(),\n", "    tf.keras.layers.Dense(128, activation='relu'),\n", "    tf.keras.layers.Dropout(0.5),\n", "    tf.keras.layers.Dense(train_data.num_classes, activation='softmax')\n", "])\n", "\n", "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n", "model.summary()\n", "\n", "# Add callbacks for early stopping and saving the best model\n", "callbacks = [\n", "    EarlyStopping(patience=3, restore_best_weights=True),\n", "    ModelCheckpoint('best_emotion_model.h5', save_best_only=True)\n", "]\n", "\n", "# Train the model with callbacks\n", "history = model.fit(train_data, validation_data=val_data, epochs=20, callbacks=callbacks)\n", "\n", "# Save the trained model\n", "model.save('emotion_model_mobilenet')\n", "\n", "# Plot training history\n", "plt.plot(history.history['accuracy'], label='Training Accuracy')\n", "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n", "plt.plot(history.history['loss'], label='Training Loss')\n", "plt.plot(history.history['val_loss'], label='Validation Loss')\n", "plt.xlabel('Epoch')\n", "plt.ylabel('Value')\n", "plt.title('Model Performance')\n", "plt.legend()\n", "plt.grid(True)\n", "plt.show()\n", "\n", "# Load the trained model and class labels for real-time detection\n", "model = tf.keras.models.load_model('emotion_model_mobilenet')\n", "class_names = list(train_data.class_indices.keys())\n", "\n", "# Initialize webcam and face detection\n", "cap = cv2.VideoCapture(0)\n", "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n", "\n", "# Start real-time emotion detection loop\n", "try:\n", "    while True:\n", "        ret, frame = cap.read()\n", "        if not ret:\n", "            print(\"Failed to grab frame.\")\n", "            break\n", "\n", "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n", "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n", "\n", "        for (x, y, w, h) in faces:\n", "            roi_color = frame[y:y+h, x:x+w]\n", "            roi_resized = cv2.resize(roi_color, (224, 224)) / 255.0\n", "            roi_expanded = np.expand_dims(roi_resized, axis=0)\n", "            prediction = model.predict(roi_expanded)\n", "            emotion = class_names[np.argmax(prediction)]\n", "            confidence = np.max(prediction)\n", "            label = f\"{emotion} ({confidence*100:.1f}%)\"\n", "\n", "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n", "            cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n", "\n", "        cv2.imshow('Emotion Detection', frame)\n", "        if cv2.waitKey(1) & 0xFF == ord('q'):\n", "            break\n", "\n", "except Exception as e:\n", "    print(f\"Error: {e}\")\n", "\n", "finally:\n", "    cap.release()\n", "    cv2.destroyAllWindows()\n", "\n", "# Optional: Predict emotion from a static image file\n", "from tensorflow.keras.preprocessing import image\n", "\n", "img = image.load_img('test.jpg', target_size=(224, 224))\n", "img_array = image.img_to_array(img) / 255.0\n", "img_array = np.expand_dims(img_array, axis=0)\n", "\n", "pred = model.predict(img_array)\n", "print(\"Predicted emotion:\", class_names[np.argmax(pred)])\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 2}