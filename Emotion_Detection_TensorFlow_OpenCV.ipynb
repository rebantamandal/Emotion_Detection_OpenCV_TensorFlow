{"nbformat": 4, "nbformat_minor": 0, "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Emotion Detection using TensorFlow and Transfer Learning\n", "This notebook implements a real-time emotion detection system using TensorFlow, transfer learning (MobileNetV2), and OpenCV for webcam input."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Install required packages\n", "!pip install tensorflow opencv-python matplotlib"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n", "import cv2\n", "import numpy as np\n", "import os\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Data Preparation\n", "Assuming the data is in a directory structure like:\n", "`data/train/emotion_class/` and `data/validation/emotion_class/`"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Create ImageDataGenerators\n", "train_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True, zoom_range=0.2)\n", "val_gen = ImageDataGenerator(rescale=1./255)\n", "\n", "train_data = train_gen.flow_from_directory(\n", "    'data/train',\n", "    target_size=(224, 224),\n", "    batch_size=32,\n", "    class_mode='categorical'\n", ")\n", "\n", "val_data = val_gen.flow_from_directory(\n", "    'data/validation',\n", "    target_size=(224, 224),\n", "    batch_size=32,\n", "    class_mode='categorical'\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Build Model with MobileNetV2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),\n", "                                               include_top=False,\n", "                                               weights='imagenet')\n", "base_model.trainable = False\n", "\n", "model = tf.keras.Sequential([\n", "    base_model,\n", "    tf.keras.layers.GlobalAveragePooling2D(),\n", "    tf.keras.layers.Dense(128, activation='relu'),\n", "    tf.keras.layers.Dropout(0.5),\n", "    tf.keras.layers.Dense(train_data.num_classes, activation='softmax')\n", "])\n", "\n", "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n", "model.summary()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train the Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["history = model.fit(train_data, validation_data=val_data, epochs=10)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Save the Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.save('emotion_model_mobilenet')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Real-Time Emotion Detection with OpenCV"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = tf.keras.models.load_model('emotion_model_mobilenet')\n", "class_names = list(train_data.class_indices.keys())\n", "\n", "cap = cv2.VideoCapture(0)\n", "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n", "\n", "while True:\n", "    ret, frame = cap.read()\n", "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n", "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n", "    for (x, y, w, h) in faces:\n", "        roi_color = frame[y:y+h, x:x+w]\n", "        roi_resized = cv2.resize(roi_color, (224, 224)) / 255.0\n", "        roi_expanded = np.expand_dims(roi_resized, axis=0)\n", "        prediction = model.predict(roi_expanded)\n", "        emotion = class_names[np.argmax(prediction)]\n", "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n", "        cv2.putText(frame, emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n", "\n", "    cv2.imshow('Emotion Detection', frame)\n", "    if cv2.waitKey(1) & 0xFF == ord('q'):\n", "        break\n", "\n", "cap.release()\n", "cv2.destroyAllWindows()"]}]}